{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad del Valle de Guatemala\n",
    "\n",
    "Minería de Datos\n",
    "\n",
    "Proyecto 2 Entrega 5\n",
    "\n",
    "Wilson Calderón, 22018\n",
    "\n",
    "Abby Donis, 22440\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación de Variables Dicotómicas \n",
    "\n",
    "Se ha creado una variable categórica partiendo de SalePrice utilizando cuantiles del 33 y 66% respectivamente. Esto permite clasificar viviendas en tres grupos. Económico, Medio y Caro. De ahí se generaron variables binarias llamadas EsCara, EsMedia y EsEconomica que toman valores 1 o 0 según corresponda. Si una casa se encuentra en el tercil superior, la variable EsCara es 1. De lo contrario es 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ---------------------\n",
    "    # Inciso 1: Crear Variables Dicotómicas a partir de SalePrice\n",
    "    # ---------------------\n",
    "    try:\n",
    "        df = pd.read_csv(\"train.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Error al cargar 'train.csv':\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Columnas del dataset:\", df.columns.tolist())\n",
    "\n",
    "    # Utilizamos los cuantiles 33% y 66% para definir los umbrales\n",
    "    quantiles = df['SalePrice'].quantile([0.33, 0.66])\n",
    "    q_low = quantiles.iloc[0]\n",
    "    q_high = quantiles.iloc[1]\n",
    "\n",
    "    def categorizar_precio(x):\n",
    "        if x >= q_high:\n",
    "            return 'cara'\n",
    "        elif x >= q_low:\n",
    "            return 'media'\n",
    "        else:\n",
    "            return 'económica'\n",
    "\n",
    "    df['Categoria'] = df['SalePrice'].apply(categorizar_precio)\n",
    "    df['EsCara'] = (df['Categoria'] == 'cara').astype(int)\n",
    "    df['EsMedia'] = (df['Categoria'] == 'media').astype(int)\n",
    "    df['EsEconomica'] = (df['Categoria'] == 'económica').astype(int)\n",
    "\n",
    "    print(\"\\nPrimeras filas con SalePrice, Categoria y variables dicotómicas:\")\n",
    "    print(df[['SalePrice', 'Categoria', 'EsCara', 'EsMedia', 'EsEconomica']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mismos conjuntos de entrenamiento y prueba\n",
    "Mismos conjuntos de entrenamiento y prueba\n",
    "Para garantizar la reproducibilidad del experimento, el dataset train.csv se dividió en conjuntos de entrenamiento del 70% y prueba del 30%. Usando la función train_test_split con random_state = 42. Así se mantiene siempre las mismas particiones en cada ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ---------------------\n",
    "    # Inciso 3: Modelo de Regresión Logística con Validación Cruzada\n",
    "    # ---------------------\n",
    "modelo = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "cv_scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"\\nExactitud promedio en validación cruzada:\", np.mean(cv_scores))\n",
    "    \n",
    "    # Entrena el modelo con el conjunto de entrenamiento completo\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelo de regresión logística\n",
    "Se utiliza un modelo de regresión logística para predecir si una vivienda es cara (variable EsCara). Este modelo ha sido entrenado con el conjunto entrenamiento y se aplicó validación cruzada (5-fold). Lo que produjo una exactitud promedio del 88.85%. Esto indica que el modelo se comporta de forma consistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Inciso 3: Modelo de Regresión Logística con Validación Cruzada\n",
    "# ---------------------\n",
    "modelo = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "cv_scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"\\nExactitud promedio en validación cruzada:\", np.mean(cv_scores))\n",
    "    \n",
    "# Entrena el modelo con el conjunto de entrenamiento completo\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Análisis del modelo\n",
    "Para evaluar el modelo se realizó un análisis de multicolinealidad mediante la matriz de correlación (ver imagen de abajo). Esta gráfica no muestra correlaciones excesivamente fuertes, por lo que es mejor para el modelo. Se examinaron OverallQual y GarageCars. Tienen coeficientes positivos y significativos, mientras que YearBuilt presenta un coeficiente negativo. La dirección y magnitud de los coeficientes, sin valores p formales, indican que algunas variables aportan de forma notable al modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Inciso 4: Análisis del Modelo \n",
    "# ---------------------\n",
    "# 4.1: Análisis de multicolinealidad mediante la matriz de correlación\n",
    "corr_matrix = X_train.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(corr_matrix, cmap='coolwarm', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "plt.title(\"Matriz de correlación de variables predictoras\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluación en el Conjunto de Prueba\n",
    "Al aplicar el modelo sobre el conjunto de prueba se obtuvo una matriz de confusión con 282 verdaderos negativos, 122 verdaderos positivos, 14 falsos positivos y 20 falsos negativos. El reporte de clasificación muestra una exactitud global de 92.24%. Esto confirma que el modelo clasifica de forma eficiente. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Inciso 5: Evaluación del Modelo en el Conjunto de Prueba\n",
    "# ---------------------\n",
    "y_pred = modelo.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "    \n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "    \n",
    "print(\"Exactitud (accuracy) en el conjunto de prueba:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Sobreajuste y curvas de aprendizaje\n",
    "Las exactitudes de la validación cruzada y  conjunto de prueba alcanzan un aproximado del 89% y 92.2% respectivamente. En conjunto con que el desempeño para la clase 0 la precisión y el recall llegan al 93% y 95%, en la clase 1 estos valores son de 90% y 86% respectivamente. Además de que el f1-score es del 94% y 88% para su clase respectiva, teniendo un buen balance. \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
