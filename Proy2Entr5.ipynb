{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad del Valle de Guatemala\n",
    "\n",
    "Minería de Datos\n",
    "\n",
    "Proyecto 2 Entrega 5\n",
    "\n",
    "Wilson Calderón, 22018\n",
    "\n",
    "Abby Donis, 22440\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación de Variables Dicotómicas \n",
    "\n",
    "Se ha creado una variable categórica partiendo de SalePrice utilizando cuantiles del 33 y 66% respectivamente. Esto permite clasificar viviendas en tres grupos. Económico, Medio y Caro. De ahí se generaron variables binarias llamadas EsCara, EsMedia y EsEconomica que toman valores 1 o 0 según corresponda. Si una casa se encuentra en el tercil superior, la variable EsCara es 1. De lo contrario es 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ---------------------\n",
    "    # Inciso 1: Crear Variables Dicotómicas a partir de SalePrice\n",
    "    # ---------------------\n",
    "    try:\n",
    "        df = pd.read_csv(\"train.csv\")\n",
    "    except Exception as e:\n",
    "        print(\"Error al cargar 'train.csv':\", e)\n",
    "        return\n",
    "\n",
    "    print(\"Columnas del dataset:\", df.columns.tolist())\n",
    "\n",
    "    # Utilizamos los cuantiles 33% y 66% para definir los umbrales\n",
    "    quantiles = df['SalePrice'].quantile([0.33, 0.66])\n",
    "    q_low = quantiles.iloc[0]\n",
    "    q_high = quantiles.iloc[1]\n",
    "\n",
    "    def categorizar_precio(x):\n",
    "        if x >= q_high:\n",
    "            return 'cara'\n",
    "        elif x >= q_low:\n",
    "            return 'media'\n",
    "        else:\n",
    "            return 'económica'\n",
    "\n",
    "    df['Categoria'] = df['SalePrice'].apply(categorizar_precio)\n",
    "    df['EsCara'] = (df['Categoria'] == 'cara').astype(int)\n",
    "    df['EsMedia'] = (df['Categoria'] == 'media').astype(int)\n",
    "    df['EsEconomica'] = (df['Categoria'] == 'económica').astype(int)\n",
    "\n",
    "    print(\"\\nPrimeras filas con SalePrice, Categoria y variables dicotómicas:\")\n",
    "    print(df[['SalePrice', 'Categoria', 'EsCara', 'EsMedia', 'EsEconomica']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mismos conjuntos de entrenamiento y prueba\n",
    "Mismos conjuntos de entrenamiento y prueba\n",
    "Para garantizar la reproducibilidad del experimento, el dataset train.csv se dividió en conjuntos de entrenamiento del 70% y prueba del 30%. Usando la función train_test_split con random_state = 42. Así se mantiene siempre las mismas particiones en cada ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ---------------------\n",
    "    # Inciso 3: Modelo de Regresión Logística con Validación Cruzada\n",
    "    # ---------------------\n",
    "modelo = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "cv_scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"\\nExactitud promedio en validación cruzada:\", np.mean(cv_scores))\n",
    "    \n",
    "    # Entrena el modelo con el conjunto de entrenamiento completo\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelo de regresión logística\n",
    "Se utiliza un modelo de regresión logística para predecir si una vivienda es cara (variable EsCara). Este modelo ha sido entrenado con el conjunto entrenamiento y se aplicó validación cruzada (5-fold). Lo que produjo una exactitud promedio del 88.85%. Esto indica que el modelo se comporta de forma consistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Inciso 3: Modelo de Regresión Logística con Validación Cruzada\n",
    "# ---------------------\n",
    "modelo = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "cv_scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"\\nExactitud promedio en validación cruzada:\", np.mean(cv_scores))\n",
    "    \n",
    "# Entrena el modelo con el conjunto de entrenamiento completo\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Análisis del modelo\n",
    "Para evaluar el modelo se realizó un análisis de multicolinealidad mediante la matriz de correlación (ver imagen de abajo). Esta gráfica no muestra correlaciones excesivamente fuertes, por lo que es mejor para el modelo. Se examinaron OverallQual y GarageCars. Tienen coeficientes positivos y significativos, mientras que YearBuilt presenta un coeficiente negativo. La dirección y magnitud de los coeficientes, sin valores p formales, indican que algunas variables aportan de forma notable al modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Inciso 4: Análisis del Modelo \n",
    "# ---------------------\n",
    "# 4.1: Análisis de multicolinealidad mediante la matriz de correlación\n",
    "corr_matrix = X_train.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(corr_matrix, cmap='coolwarm', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "plt.title(\"Matriz de correlación de variables predictoras\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluación en el Conjunto de Prueba\n",
    "Al aplicar el modelo sobre el conjunto de prueba se obtuvo una matriz de confusión con 282 verdaderos negativos, 122 verdaderos positivos, 14 falsos positivos y 20 falsos negativos. El reporte de clasificación muestra una exactitud global de 92.24%. Esto confirma que el modelo clasifica de forma eficiente. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Inciso 5: Evaluación del Modelo en el Conjunto de Prueba\n",
    "# ---------------------\n",
    "y_pred = modelo.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(cm)\n",
    "    \n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "    \n",
    "print(\"Exactitud (accuracy) en el conjunto de prueba:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Sobreajuste y curvas de aprendizaje\n",
    "Las exactitudes de la validación cruzada y  conjunto de prueba alcanzan un aproximado del 89% y 92.2% respectivamente. En conjunto con que el desempeño para la clase 0 la precisión y el recall llegan al 93% y 95%, en la clase 1 estos valores son de 90% y 86% respectivamente. Además de que el f1-score es del 94% y 88% para su clase respectiva, teniendo un buen balance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tuneo de modelo \n",
    "Al haber aplicado el tuneo para el modelo podemos ver que los mejores parametros fueron L2 para tipo de regularización, con una fuerza de 1 y el algoritmo liblinear. La exactitud logró mejorar al 93.6% indicando que el tuneo fue efectivo al subir del 92.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Inciso 7: Tuneo curva de aprendizaje\n",
    "# ------------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "#busca parametro\n",
    "param_grid = {\n",
    "'model__penalty': ['l1', 'l2'],\n",
    "'model__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "'model__solver': ['liblinear', 'saga']\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"\\nMejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Exactitud:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Análisis de eficiencia del algoritmo\n",
    "Podemos ver que hay un total de 281 verdaderos negativos, 129 verdaderos positivos, 15 13 falsos negativos y 15 falsos positivos. De esto, se marca como error el 5.07% de los falsos positivos y el 9.15% de falsos negativos, al comparar podemos ver que hubo una mejora en los falsos positivos y negativos. \n",
    "En cuanto a los tiempos de ejecución el entrenamiento lleva 0.0235 segundos, bastante óptimo. Las funciones más costosas son train_and_predict (0.024s), el procesamiento de pipeline (0.017s) y la validación de los datos (0.013s), la memoria realiza 9214 llamadas a funciones y hay un uso moderado de recursos según el perfilado.\n",
    "Completando con la información que acabamos de obtener podemos decir que el modelo es bastante efectivo. Esto ya que hay un buen balance entre precisión (92.85%),  rendimiento (tiempos de ejecución bastante bajos) y estabilidad (bajo consumo de recursos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ------------------------------\n",
    "    # Inciso 8: Matriz de confusion y rendimiento\n",
    "    # ------------------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de Confusion (Tuneo):\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n**ANÁLISIS DE RENDIMIENTO**\")\n",
    "# Análisis detallado de errores\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nDetalle de errores:\")\n",
    "print(f\"- Falsos Positivos (FP): {fp} casos - Viviendas normales clasificadas como caras\")\n",
    "print(f\"- Falsos Negativos (FN): {fn} casos - Viviendas caras clasificadas como normales\")\n",
    "print(f\"\\nTasa de error FP: {fp/(fp+tn):.2%}\")\n",
    "print(f\"Tasa de error FN: {fn/(fn+tp):.2%}\")\n",
    "\n",
    "# Análisis de rendimiento con cProfile\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\n**DETALLE DE ERRORES**\")\n",
    "print(f\"Falsos Positivos (FP): {fp} casos - Viviendas normales clasificadas como caras\")\n",
    "print(f\"Falsos Negativos (FN): {fn} casos - Viviendas caras clasificadas como normales\")\n",
    "print(f\"\\nTasa de error FP: {fp/(fp+tn):.2%}\")\n",
    "print(f\"Tasa de error FN: {fn/(fn+tp):.2%}\")\n",
    "\n",
    "# Función para análisis de rendimiento\n",
    "print(\"\\n**ANÁLISIS DE RENDIMIENTO**\")\n",
    "print(\"=== Resultados del perfilado ===\")\n",
    "def profile(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        pr = cProfile.Profile()\n",
    "        pr.enable()\n",
    "        start_time = time.time()\n",
    "            \n",
    "        result = func(*args, **kwargs)\n",
    "            \n",
    "        end_time = time.time()\n",
    "        pr.disable()\n",
    "            \n",
    "        print(f\"\\nTiempo de ejecución: {end_time - start_time:.4f} segundos\")\n",
    "            \n",
    "        s = io.StringIO()\n",
    "        ps = pstats.Stats(pr, stream=s).sort_stats('cumtime')\n",
    "        ps.print_stats(10)\n",
    "        print(s.getvalue())\n",
    "            \n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "    # Función a analizar\n",
    "    @profile\n",
    "    def train_and_predict():\n",
    "        model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(penalty='l2', C=1, solver='liblinear', max_iter=1000))\n",
    "        ])\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    train_and_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Mejor modelo\n",
    "Comparando modelos desarrollados, se evaluaron tanto las métricas de desempeño como exactitud, precisión y más con criterios de complejidad AIC y BIC con tiempos de ejecución. Con esto, vemos que el modelo de Regresión Logística optimizado mostró un buen equilibrio entre precisión, eficiencia y complejidad. \n",
    "Podemos ver que el modelo tiene un excelente desempeño con métricas AIC y BIC bajas, indicando un buen ajuste estadístico.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Inciso 9: Mejor modelo\n",
    "# ------------------------------\n",
    "aic_bin, bic_bin = aic_bic(best_model.named_steps['model'], X_test, y_test)\n",
    "print(\"\\nMetricas estadisticas:\")\n",
    "print(f\"AIC: {aic_bin:.2f} | BIC: {bic_bin:.2f}\")\n",
    "print(\"(Valores mas bajos indican mejor modelo)\")\n",
    "#matriz\n",
    "y_pred_bin = best_model.predict(X_test)\n",
    "cm_bin = confusion_matrix(y_test, y_pred_bin)\n",
    "tn, fp, fn, tp = cm_bin.ravel()\n",
    "    \n",
    "print(\"\\nAnálisis de errores:\")\n",
    "print(f\"FP (Sobrestimación): {fp} casos ({fp/(fp+tn):.2%})\")\n",
    "print(f\"FN (Subestimación): {fn} casos ({fn/(fn+tp):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Regresión logística para variable categórica\n",
    "Se implementó una regresión logística para predecir el precio de las viviendas entre baratas, medias y caras. Luego de ajustar los hiper-parámetros mediante validación cruzada, se mostró un buen desempeño. Esto se ve en la matriz de confusión y reporte de clasificación. Sin embargo, podemos ver cierta dificultad con la clasificación de casas en la categoría “cara” al tener un recall bastante bajo de 52% y un f1-score del 62%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Inciso 10: Regresion para variable de precios\n",
    "# ------------------------------\n",
    "X_multi = df[features]\n",
    "y_multi = LabelEncoder().fit_transform(df['Categoria'])  # 0:barata, 1:media, 2:cara\n",
    "    \n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.3, random_state=42)\n",
    "    \n",
    "# Pipeline y parametros\n",
    " multi_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', OneVsRestClassifier(LogisticRegression(max_iter=1000)))\n",
    "])\n",
    "param_grid = {\n",
    "    'model__estimator__C': [0.1, 1, 10],\n",
    "    'model__estimator__penalty': ['l2'],\n",
    "    'model__estimator__solver': ['liblinear', 'saga']\n",
    "}\n",
    "print(\"\\nTUNEADO MULTICASE\")\n",
    "grid_multi = GridSearchCV(multi_pipe, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_multi.fit(X_train_m, y_train_m)\n",
    "    \n",
    "best_multi = grid_multi.best_estimator_\n",
    "print(\"\\nMejores parametros:\", grid_multi.best_params_)\n",
    "\n",
    "y_pred_multi = best_multi.predict(X_test_m)\n",
    "print(\"\\nReporte clasificacion:\")\n",
    "print(classification_report(y_test_m, y_pred_multi, target_names=['Económica', 'Media', 'Cara']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Comparación de eficiencia de modelos\n",
    "Se compararon los modelos anteriores y este. La comparación reveló cuál modelo logra un mejor balance entre eficiencia y precisión de esta clasificación. En base a los resultados, el modelo binario es más rápido y preciso, esto puede explicarse gracias a que este es más simple. Aunque cabe destacar que el Multicase de un poco de información más detallada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Inciso 11: Comparación de eficiencia de modelos\n",
    "# ------------------------------\n",
    "@profile\n",
    "def evaluate_model(model, X_train, y_train, X_test):\n",
    "    start_e = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = max(time.time() - start_e, 0.000001)\n",
    "        \n",
    "    start_p = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_time = max(time.time() - start_p, 0.000001)\n",
    "        \n",
    "    return {\n",
    "        'Tiempo Entrenamiento': train_time,\n",
    "        'Tiempo Predicción': pred_time,\n",
    "        'Exactitud': accuracy_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    #Ev y comparacion\n",
    "    #binario\n",
    "    res_bin = evaluate_model(best_model, X_train, y_train, X_test)\n",
    "    #multicase\n",
    "    res_multi = evaluate_model(best_multi, X_train_m, y_train_m, X_test_m)\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Binario': res_bin,\n",
    "        'Multiclase': res_multi\n",
    "    }).T\n",
    "    print(\"\\nTabla comparativa:\")\n",
    "    print(comparison)\n",
    "    \n",
    "    print(\"\\n*** CONCLUSIONES ***\")\n",
    "    print(\"Rendimiento computacional:\")\n",
    "    print(\"  - Tiempo (mas lento):\")\n",
    "    print(f\"   Entrenamiento: {res_multi['Tiempo Entrenamiento']/res_bin['Tiempo Entrenamiento']:.1f}x\")\n",
    "    print(f\"   Prediccion:    {res_multi['Tiempo Predicción']/res_bin['Tiempo Predicción']:.1f}x\")\n",
    "    \n",
    "    print(\"\\nPrecisión:\")\n",
    "    print(f\"   Binario: {res_bin['Exactitud']:.2%} de exactitud\")\n",
    "    print(f\"   Multiclase: {res_multi['Exactitud']:.2%} de exactitud\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
